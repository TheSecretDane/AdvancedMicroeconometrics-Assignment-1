@online{ahrensIntroductionDoubleDebiased2025,
  title = {An {{Introduction}} to {{Double}}/{{Debiased Machine Learning}}},
  author = {Ahrens, Achim and Chernozhukov, Victor and Hansen, Christian and Kozbur, Damian and Schaffer, Mark and Wiemann, Thomas},
  date = {2025-04-11},
  eprint = {2504.08324},
  eprinttype = {arXiv},
  eprintclass = {econ},
  doi = {10.48550/arXiv.2504.08324},
  urldate = {2025-10-30},
  abstract = {This paper provides a practical introduction to Double/Debiased Machine Learning (DML). DML provides a general approach to performing inference about a target parameter in the presence of nuisance parameters. The aim of DML is to reduce the impact of nuisance parameter estimation on estimators of the parameter of interest. We describe DML and its two essential components: Neyman orthogonality and cross-fitting. We highlight that DML reduces functional form dependence and accommodates the use of complex data types, such as text data. We illustrate its application through three empirical examples that demonstrate DML's applicability in cross-sectional and panel settings.},
  pubstate = {prepublished},
  keywords = {Economics - Econometrics,Statistics - Machine Learning,Statistics - Methodology},
  file = {C\:\\Users\\mathi\\OneDrive - University of Copenhagen\\zotero_db\\Courses\\Advanced Microeconometrics\\Ahrens et al. - 2025 - An Introduction to DoubleDebiased Machine Learning.pdf;C\:\\Users\\mathi\\Zotero\\storage\\E59ZWS7B\\2504.html}
}

@article{barroEconomicGrowthCrosssection,
  title = {Economic {{Growth}} in a Cross-Section of Countries},
  author = {Barro, Robert},
  abstract = {In neoclassical growth models with diminishing returns to capital, a country's per capita growth rate tends to be inversely related to its initial level of income per person. This convergence hypothesis seems to be inconsistent with the cross-country evidence, which indicates that per capita growth rates for about 100 countries in the post-World War II period are uncorrelated with the starting level of per capita product. However, if one holds constant measures of initial human capital‚Äîmeasured by primary and secondary school-enrollment rates‚Äîthere is evidence that countries with lower per capita product tend to grow faster. Countries with higher human capital also have lower fertility rates and higher ratios of physical investment to GDP. These results on growth, fertility, and investment are consistent with some recent theories of endogenous economic growth. With regard to government, the cross-country data indicate that government consumption is inversely related to growth, whereas public investment has little relation with growth. Average growth rates are positively related to political stability, which may capture the benefits of secure property rights. There is also some indication that distortions of investment-goods prices are adverse for growth. Finally, the analysis leaves unexplained a good deal of the relatively weak growth performances of countries in sub- Saharan Africa and Latin America.},
  langid = {english},
  file = {C:\Users\mathi\OneDrive - University of Copenhagen\zotero_db\Courses\Advanced Microeconometrics\w3120.pdf}
}

@article{belloniHighDimensionalMethodsInference2014,
  title = {High-{{Dimensional Methods}} and {{Inference}} on {{Structural}} and {{Treatment Effects}}},
  author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian},
  date = {2014-05-01},
  journaltitle = {Journal of Economic Perspectives},
  shortjournal = {Journal of Economic Perspectives},
  volume = {28},
  number = {2},
  pages = {29--50},
  issn = {0895-3309},
  doi = {10.1257/jep.28.2.29},
  urldate = {2025-10-30},
  abstract = {Data with a large number of variables relative to the sample size‚Äî‚Äúhigh-dimensional data‚Äù‚Äîare readily available and increasingly common in empirical economics. Highdimensional data arise through a combination of two phenomena. First, the data may be inherently high dimensional in that many different characteristics per observation are available. For example, the US Census collects information on hundreds of individual characteristics and scanner datasets record transaction-level data for households across a wide range of products. Second, even when the number of available variables is relatively small, researchers rarely know the exact functional form with which the small number of variables enter the model of interest. Researchers are thus faced with a large set of potential variables formed by different ways of interacting and transforming the underlying variables. This paper provides an overview of how innovations in ‚Äúdata mining‚Äù can be adapted and modified to provide high-quality inference about model parameters. Note that we use the term ‚Äúdata mining‚Äù in a modern sense which denotes a principled search for ‚Äútrue‚Äù predictive power that guards against false discovery and overfitting, does not erroneously equate in-sample fit to out-of-sample predictive ability, and accurately accounts for using the same data to examine many different hypotheses or models.},
  langid = {english},
  annotation = {483 citations (Crossref/DOI) [2025-12-08]},
  file = {C:\Users\mathi\OneDrive - University of Copenhagen\zotero_db\Courses\Advanced Microeconometrics\Belloni, Chernozhukov, Hansen [2014 J Econ Perspec] High-Dimensional Methods and Inference on Structural and Treatment Effects.pdf}
}

@online{belloniHighDimensionalSparse2011,
  title = {High {{Dimensional Sparse Econometric Models}}: {{An Introduction}}},
  shorttitle = {High {{Dimensional Sparse Econometric Models}}},
  author = {Belloni, Alexandre and Chernozhukov, Victor},
  date = {2011-09-02},
  eprint = {1106.5242},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.1106.5242},
  urldate = {2025-10-30},
  abstract = {In this chapter we discuss conceptually high dimensional sparse econometric models as well as estimation of these models using L1-penalization and post-L1-penalization methods. Focusing on linear and nonparametric regression frameworks, we discuss various econometric examples, present basic theoretical results, and illustrate the concepts and methods with Monte Carlo simulations and an empirical application. In the application, we examine and confirm the empirical validity of the Solow-Swan model for international economic growth.},
  pubstate = {prepublished},
  keywords = {Economics - Econometrics,Statistics - Applications,Statistics - Methodology},
  file = {C\:\\Users\\mathi\\OneDrive - University of Copenhagen\\zotero_db\\Courses\\Advanced Microeconometrics\\Belloni and Chernozhukov - 2011 - High Dimensional Sparse Econometric Models An Introduction.pdf;C\:\\Users\\mathi\\Zotero\\storage\\6HF5BT3A\\1106.html}
}

@article{belloniInferenceTreatmentEffects2014,
  title = {Inference on {{Treatment Effects}} after {{Selection}} among {{High-Dimensional Controls}}},
  author = {Belloni, A. and Chernozhukov, V. and Hansen, C.},
  date = {2014-04-01},
  journaltitle = {The Review of Economic Studies},
  shortjournal = {The Review of Economic Studies},
  volume = {81},
  number = {2},
  pages = {608--650},
  issn = {0034-6527, 1467-937X},
  doi = {10.1093/restud/rdt044},
  urldate = {2025-10-29},
  abstract = {We propose robust methods for inference about the effect of a treatment variable on a scalar outcome in the presence of very many regressors in a model with possibly non-Gaussian and heteroscedastic disturbances. We allow for the number of regressors to be larger than the sample size. To make informative inference feasible, we require the model to be approximately sparse; that is, we require that the effect of confounding factors can be controlled for up to a small approximation error by including a relatively small number of variables whose identities are unknown. The latter condition makes it possible to estimate the treatment effect by selecting approximately the right set of regressors. We develop a novel estimation and uniformly valid inference method for the treatment effect in this setting, called the ‚Äúpost-double-selection‚Äù method. The main attractive feature of our method is that it allows for imperfect selection of the controls and provides confidence intervals that are valid uniformly across a large class of models. In contrast, standard post-model selection estimators fail to provide uniform inference even in simple cases with a small, fixed number of controls. Thus, our method resolves the problem of uniform inference after model selection for a large, interesting class of models. We also present a generalization of our method to a fully heterogeneous model with a binary treatment variable. We illustrate the use of the developed methods with numerical simulations and an application that considers the effect of abortion on crime rates.},
  langid = {english},
  annotation = {1051 citations (Crossref/DOI) [2025-12-08]},
  file = {C:\Users\mathi\OneDrive - University of Copenhagen\zotero_db\rdt044.pdf}
}

@article{belloniSparseModelsMethods2012,
  title = {Sparse {{Models}} and {{Methods}} for {{Optimal Instruments}} with an {{Application}} to {{Eminent Domain}}},
  author = {Belloni, A. and Chen, D. and Chernozhukov, V. and Hansen, C.},
  date = {2012},
  journaltitle = {Econometrica},
  volume = {80},
  number = {6},
  pages = {2369--2429},
  publisher = {[Wiley, Econometric Society]},
  issn = {0012-9682},
  doi = {10.3982/ECTA9626},
  urldate = {2025-10-30},
  abstract = {We develop results for the use of Lasso and post-Lasso methods to form first-stage predictions and estimate optimal instruments in linear instrumental variables (IV) models with many instruments, p. Our results apply even when p is much larger than the sample size, n. We show that the IV estimator based on using Lasso or post-Lasso in the first stage is root-n consistent and asymptotically normal when the first stage is approximately sparse, that is, when the conditional expectation of the endogenous variables given the instruments can be well-approximated by a relatively small set of variables whose identities may be unknown. We also show that the estimator is semiparametrically efficient when the structural error is homoscedastic. Notably, our results allow for imperfect model selection, and do not rely upon the unrealistic "beta-min" conditions that are widely used to establish validity of inference following model selection (see also Belloni, Chernozhukov, and Hansen (2011b)). In simulation experiments, the Lasso-based IV estimator with a data-driven penalty performs well compared to recently advocated many-instrument robust procedures. In an empirical example dealing with the effect of judicial eminent domain decisions on economic outcomes, the Lasso-based IV estimator outperforms an intuitive benchmark. Optimal instruments are conditional expectations. In developing the IV results, we establish a series of new results for Lasso and post-Lasso estimators of nonparametric conditional expectation functions which are of independent theoretical and practical interest. We construct a modification of Lasso designed to deal with non-Gaussian, heteroscedastic disturbances that uses a data-weighted ùìÅ‚ÇÅ-penalty function. By innovatively using moderate deviation theory for self-normalized sums, we provide convergence rates for the resulting Lasso and post-Lasso estimators that are as sharp as the corresponding rates in the homoscedastic Gaussian case under the condition that log p = o(n 1/3 ). We also provide a data-driven method for choosing the penalty level that must be specified in obtaining Lasso and post-Lasso estimates and establish its asymptotic validity under non-Gaussian, heteroscedastic disturbances.},
  annotation = {616 citations (Crossref/DOI) [2025-12-08]},
  file = {C:\Users\mathi\OneDrive - University of Copenhagen\zotero_db\Courses\Advanced Microeconometrics\Belloni et al. - 2012 - Sparse Models and Methods for Optimal Instruments with an Application to Eminent Domain.pdf}
}

@article{chernozhukovDoubleDebiasedMachine2018,
  title = {Double/Debiased Machine Learning for Treatment and Structural Parameters},
  author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
  date = {2018-02-01},
  journaltitle = {The Econometrics Journal},
  volume = {21},
  number = {1},
  pages = {C1-C68},
  issn = {1368-4221, 1368-423X},
  doi = {10.1111/ectj.12097},
  urldate = {2025-10-30},
  langid = {english},
  annotation = {1671 citations (Crossref/DOI) [2025-12-08]},
  file = {C:\Users\mathi\OneDrive - University of Copenhagen\zotero_db\Courses\Advanced Microeconometrics\ectj00c1.pdf}
}

@article{fryerEmpiricalAnalysisRacial2019,
  title = {An {{Empirical Analysis}} of {{Racial Differences}} in {{Police Use}} of {{Force}}},
  author = {Fryer, Roland G.},
  date = {2019},
  journaltitle = {Journal of Political Economy},
  volume = {127},
  number = {3},
  eprint = {26846673},
  eprinttype = {jstor},
  pages = {1210--1261},
  publisher = {The University of Chicago Press},
  issn = {0022-3808},
  urldate = {2025-11-26},
  abstract = {This paper explores racial differences in police use of force. On nonlethal uses of force, blacks and Hispanics are more than 50 percent more likely to experience some form of force in interactions with police. Adding controls that account for important context and civilian behavior reduces, but cannot fully explain, these disparities. On the most extreme use of force‚Äîofficer-involved shootings‚Äîwe find no racial differences either in the raw data or when contextual factors are taken into account. We argue that the patterns in the data are consistent with a model in which police officers are utility maximizers, a fraction of whom have a preference for discrimination, who incur relatively high expected costs of officer-involved shootings.},
  file = {C:\Users\mathi\OneDrive - University of Copenhagen\zotero_db\Courses\Advanced Microeconometrics\Fryer - 2019 - An Empirical Analysis of Racial Differences in Police Use of Force.pdf}
}

@online{hirshbergDebiasedInferenceAverage2018,
  title = {Debiased {{Inference}} of {{Average Partial Effects}} in {{Single-Index Models}}},
  author = {Hirshberg, David A. and Wager, Stefan},
  date = {2018-11-06},
  eprint = {1811.02547},
  eprinttype = {arXiv},
  eprintclass = {math},
  doi = {10.48550/arXiv.1811.02547},
  urldate = {2025-12-04},
  abstract = {We propose a method for average partial effect estimation in high-dimensional single-index models that is root-n-consistent and asymptotically unbiased given sparsity assumptions on the underlying regression model. This note was prepared as a comment on Wooldridge and Zhu [2018], forthcoming in the Journal of Business and Economic Statistics.},
  pubstate = {prepublished},
  keywords = {Mathematics - Statistics Theory},
  file = {C\:\\Users\\mathi\\OneDrive - University of Copenhagen\\zotero_db\\Courses\\Advanced Microeconometrics\\Hirshberg and Wager - 2018 - Debiased Inference of Average Partial Effects in Single-Index Models.pdf;C\:\\Users\\mathi\\Zotero\\storage\\9VEMGC2T\\1811.html}
}

@article{knoxAdministrativeRecordsMask2020,
  title = {Administrative {{Records Mask Racially Biased Policing}}},
  author = {Knox, Dean and Lowe, Will and Mummolo, Jonathan},
  date = {2020-08},
  journaltitle = {American Political Science Review},
  volume = {114},
  number = {3},
  pages = {619--637},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055420000039},
  urldate = {2025-11-26},
  abstract = {Researchers often lack the necessary data to credibly estimate racial discrimination in policing. In particular, police administrative records lack information on civilians police observe but do not investigate. In this article, we show that if police racially discriminate when choosing whom to investigate, analyses using administrative records to estimate racial discrimination in police behavior are statistically biased, and many quantities of interest are unidentified‚Äîeven among investigated individuals‚Äîabsent strong and untestable assumptions. Using principal stratification in a causal mediation framework, we derive the exact form of the statistical bias that results from traditional estimation. We develop a bias-correction procedure and nonparametric sharp bounds for race effects, replicate published findings, and show the traditional estimator can severely underestimate levels of racially biased policing or mask discrimination entirely. We conclude by outlining a general and feasible design for future studies that is robust to this inferential snare.},
  langid = {english},
  annotation = {183 citations (Crossref/DOI) [2025-12-08]},
  file = {C:\Users\mathi\OneDrive - University of Copenhagen\zotero_db\Courses\Advanced Microeconometrics\Knox et al. - 2020 - Administrative Records Mask Racially Biased Policing.pdf}
}

@online{MessengerFacebook,
  title = {Messenger | {{Facebook}}},
  urldate = {2025-12-05},
  file = {C:\Users\mathi\Zotero\storage\Z5UHYXJT\659717570494352.html}
}

@article{puhrFirthsLogisticRegression2017,
  title = {Firth's Logistic Regression with Rare Events: Accurate Effect Estimates {{AND}} Predictions?},
  shorttitle = {Firth's Logistic Regression with Rare Events},
  author = {Puhr, Rainer and Heinze, Georg and Nold, Mariana and Lusa, Lara and Geroldinger, Angelika},
  date = {2017-06-30},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statistics in Medicine},
  volume = {36},
  number = {14},
  eprint = {2101.07620},
  eprinttype = {arXiv},
  eprintclass = {stat},
  pages = {2302--2317},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.7273},
  urldate = {2025-12-04},
  abstract = {Firth-type logistic regression has become a standard approach for the analysis of binary outcomes with small samples. Whereas it reduces the bias in maximum likelihood estimates of coefficients, bias towards 1/2 is introduced in the predicted probabilities. The stronger the imbalance of the outcome, the more severe is the bias in the predicted probabilities. We propose two simple modifications of Firth-type logistic regression resulting in unbiased predicted probabilities. The first corrects the predicted probabilities by a post-hoc adjustment of the intercept. The other is based on an alternative formulation of Firth-types estimation as an iterative data augmentation procedure. Our suggested modification consists in introducing an indicator variable which distinguishes between original and pseudo observations in the augmented data. In a comprehensive simulation study these approaches are compared to other attempts to improve predictions based on Firth-type penalization and to other published penalization strategies intended for routine use. For instance, we consider a recently suggested compromise between maximum likelihood and Firth-type logistic regression. Simulation results are scrutinized both with regard to prediction and regression coefficients. Finally, the methods considered are illustrated and compared for a study on arterial closure devices in minimally invasive cardiac surgery.},
  keywords = {Statistics - Methodology},
  annotation = {302 citations (Crossref/DOI) [2025-12-08]},
  file = {C\:\\Users\\mathi\\OneDrive - University of Copenhagen\\zotero_db\\Courses\\Advanced Microeconometrics\\Puhr et al. - 2017 - Firth's logistic regression with rare events accurate effect estimates AND predictions.pdf;C\:\\Users\\mathi\\Zotero\\storage\\FSNT2NJY\\2101.html}
}

@article{sala-i-martinJustRanTwo1997,
  title = {I {{Just Ran Two Million Regressions}}},
  author = {Sala-I-Martin, Xavier X.},
  date = {1997},
  journaltitle = {The American Economic Review},
  volume = {87},
  number = {2},
  eprint = {2950909},
  eprinttype = {jstor},
  pages = {178--183},
  publisher = {American Economic Association},
  issn = {0002-8282},
  urldate = {2026-01-17},
  file = {C:\Users\mathi\OneDrive - University of Copenhagen\zotero_db\Courses\Advanced Microeconometrics\Sala-I-Martin - 1997 - I Just Ran Two Million Regressions.pdf}
}

@book{wooldridgeEconometricAnalysisCross2010,
  title = {Econometric Analysis of Cross Section and Panel Data},
  author = {Wooldridge, Jeffrey M.},
  date = {2010},
  publisher = {MIT press},
  keywords = {Advanced Microeconometrics,Econometrics,Panel Data},
  file = {C:\Users\mathi\Zotero\storage\97QTTEEG\Wooldridge - 2010 - Econometric analysis of cross section and panel data.pdf}
}
